{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9533b8be",
   "metadata": {},
   "source": [
    "# Correlation Matrix with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd4d47b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adc85d4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1482436a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['teste', 'pyproject.toml', 'report', 'weights', 'notebooks', 'requirements.txt', 'data', '.gitignore', 'README.md', 'Makefile', 'parkinson', '.git']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "print(os.listdir('../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "affa8df1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (graph.py, line 130)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[36m(most recent call last)\u001b[39m:\n",
      "  File \u001b[92m~/miniconda3/envs/trabRN/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3672\u001b[39m in \u001b[95mrun_code\u001b[39m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  Cell \u001b[92mIn[3]\u001b[39m\u001b[92m, line 8\u001b[39m\n    import parkinson\n",
      "  File \u001b[92m~/facul/RedesNeurais/Parkinson-Diagnosis-Deeplearning/notebooks/../parkinson/__init__.py:1\u001b[39m\n    from . import utils\n",
      "\u001b[36m  \u001b[39m\u001b[36mFile \u001b[39m\u001b[32m~/facul/RedesNeurais/Parkinson-Diagnosis-Deeplearning/notebooks/../parkinson/utils/__init__.py:2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mfrom . import graph\u001b[39m\n",
      "  \u001b[36mFile \u001b[39m\u001b[32m~/facul/RedesNeurais/Parkinson-Diagnosis-Deeplearning/notebooks/../parkinson/utils/graph.py:130\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m!ls\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# sys.path.append('/home/labic/merlin_codes/dl/Parkinson-Diagnosis-Deeplearning')\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "import time\n",
    "    \n",
    "import parkinson\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28f7899",
   "metadata": {},
   "outputs": [],
   "source": [
    "RDN = 50\n",
    "N_CLASSES = 2\n",
    "BATCH_SIZE = 32\n",
    "N_EPOCHS = 200\n",
    "PATIENCE = 20\n",
    "LR = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccc346b",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "### Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3806cc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:04<00:00, 37.56it/s]\n",
      "100%|██████████| 66/66 [00:01<00:00, 38.27it/s]\n"
     ]
    }
   ],
   "source": [
    "parkinson_data = parkinson.utils.data.batch_read('../data/PDs_columns')\n",
    "control_data = parkinson.utils.data.batch_read('../data/Controls_columns')\n",
    "\n",
    "control_atlas_data = parkinson.utils.data.select_atlas_columns(control_data, 'AAL3')\n",
    "parkinson_atlas_data = parkinson.utils.data.select_atlas_columns(parkinson_data, 'AAL3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3bd277",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_method = \"dtw\"  # ou \"pearson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0641156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 153 pacientes\n",
      "Já computados: 0\n",
      "Restantes: 153\n",
      "\n",
      "Processando batch 0 a 5...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m parkinson_correlation_matrix = \u001b[43mparkinson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_correlation_matrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparkinson_atlas_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcorrelation_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mparkinson\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m      3\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/facul/RedesNeurais/Parkinson-Diagnosis-Deeplearning/notebooks/../parkinson/utils/graph.py:140\u001b[39m, in \u001b[36mcompute_correlation_matrix\u001b[39m\u001b[34m(time_series_list, method, group)\u001b[39m\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    139\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgroup deve ser \u001b[39m\u001b[33m'\u001b[39m\u001b[33mparkinson\u001b[39m\u001b[33m'\u001b[39m\u001b[33m ou \u001b[39m\u001b[33m'\u001b[39m\u001b[33mcontrol\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompute_all_dtw_matrices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_series_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMétodo desconhecido: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/facul/RedesNeurais/Parkinson-Diagnosis-Deeplearning/notebooks/../parkinson/utils/graph.py:93\u001b[39m, in \u001b[36mcompute_all_dtw_matrices\u001b[39m\u001b[34m(time_series_list, cache_path, final_cache_path, n_jobs)\u001b[39m\n\u001b[32m     89\u001b[39m batch_indices = indices_to_process[batch_start:batch_start + n_jobs]\n\u001b[32m     91\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mProcessando batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_start\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_start\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(batch_indices)\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m new_results = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_and_save\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_indices\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# Atualiza o cache com os resultados do batch\u001b[39;00m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, res \u001b[38;5;129;01min\u001b[39;00m new_results:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/trabRN/lib/python3.12/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/trabRN/lib/python3.12/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/trabRN/lib/python3.12/site-packages/joblib/parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "parkinson_correlation_matrix = parkinson.utils.graph.compute_correlation_matrix(\n",
    "    parkinson_atlas_data, method=correlation_method, group='parkinson'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fc39f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando cache existente de cache_dtw_control.pkl...\n",
      "Total: 66 pacientes\n",
      "Já computados: 66\n",
      "Restantes: 0\n",
      "\n",
      "Resultado final salvo em cache_dtw_control_final.pkl\n"
     ]
    }
   ],
   "source": [
    "control_correlation_matrix = parkinson.utils.graph.compute_correlation_matrix(\n",
    "    control_atlas_data, method=correlation_method, group='control'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facee837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# com pearson (descomentar se quiser usar pearson ao invés de DTW)\n",
    "# parkinson_correlation_matrix = [parkinson.utils.graph.compute_correlation_matrix(time_series) for time_series in parkinson_atlas_data]\n",
    "# control_correlation_matrix = [parkinson.utils.graph.compute_correlation_matrix(time_series) for time_series in control_atlas_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b34b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = parkinson.utils.data.concatenate_data(parkinson_correlation_matrix, control_correlation_matrix)\n",
    "y = parkinson.utils.data.concatenate_data([1 for _ in range(len(parkinson_data))], [0 for _ in range(len(control_data))])\n",
    "\n",
    "X, y = parkinson.utils.data.filter_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b6e49e",
   "metadata": {},
   "source": [
    "### Split  \n",
    "- 60% treino\n",
    "- 20% validação\n",
    "- 20% teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ee854e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, random_state=RDN, stratify=y, shuffle=True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.25, random_state=RDN, stratify=y_trainval, shuffle=True)\n",
    "\n",
    "ros = RandomOverSampler(random_state=RDN)\n",
    "X_train, y_train = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5f5cff",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c7da4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = parkinson.utils.data.get_torch_dataloader(X_train, y_train, batch_size=BATCH_SIZE)\n",
    "val_loader = parkinson.utils.data.get_torch_dataloader(X_val, y_val, batch_size=BATCH_SIZE)\n",
    "test_loader = parkinson.utils.data.get_torch_dataloader(X_test, y_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf5fe79",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eea3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = parkinson.NetworkModels.SimpleMLP(input_dim=X_train.shape[1], hidden_dim=16, output_dim=2)\n",
    "class_weights = parkinson.utils.data.get_torch_class_weights(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b070166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16a618c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-loss: 0.7036  train-acc: 0.5000 | val-loss: 0.7667  val-acc: 0.2955:  16%|█▋        | 33/200 [00:11<00:59,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 34\n",
      "CPU times: user 7.86 s, sys: 9.67 s, total: 17.5 s\n",
      "Wall time: 12.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "out = parkinson.utils.train.train(model, train_loader, val_loader, class_weights, device, N_EPOCHS,  PATIENCE,LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd89ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Metrics: {'acc': 0.29545454545454547, 'f1': 0.13476874003189793, 'recall': 0.29545454545454547, 'precision': 0.08729338842975208}\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/calixto/miniconda3/envs/trabRN/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "metrics = parkinson.utils.train.evaluate(model, test_loader, device)\n",
    "print('Metrics:', metrics)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7c4a9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m val_loss =  \u001b[43ms\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      4\u001b[39m plt.plot(np.arange(\u001b[38;5;28mlen\u001b[39m(val_loss)), val_loss)\n",
      "\u001b[31mNameError\u001b[39m: name 's' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "val_loss =  s['val_loss']\n",
    "plt.plot(np.arange(len(val_loss)), val_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trabRN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
