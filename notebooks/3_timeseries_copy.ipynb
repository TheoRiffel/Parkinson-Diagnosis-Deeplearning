{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb728e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85bf098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "os.chdir('..')\n",
    "!export PYTHONPATH=$(pwd):$PYTHONPATH\n",
    "import parkinson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a665f1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "RDN = 50\n",
    "N_CLASSES = 2\n",
    "BATCH_SIZE = 64\n",
    "N_EPOCHS = 200\n",
    "PATIENCE = 20\n",
    "LR = 0.0001\n",
    "DECAY = 0.000001\n",
    "SAVE_PATH = 'outputs/3_timeseries'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba6c920",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0117c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data from files.\n",
    "print('Started file reading...')\n",
    "parkinson_data = parkinson.utils.data.batch_read('data/PDs_columns')\n",
    "control_data = parkinson.utils.data.batch_read('data/Controls_columns')\n",
    "print('File reading completed.')\n",
    "\n",
    "# Selecting the atlas (brain division strategy: Shen_268 or atlas or AAL3).\n",
    "control_atlas_data = parkinson.utils.data.select_atlas_columns(control_data, 'AAL3')\n",
    "parkinson_atlas_data = parkinson.utils.data.select_atlas_columns(parkinson_data, 'AAL3')\n",
    "\n",
    "# Turning the selected data in time series (shape = [n_pacientes, n_channels, n_observations]).\n",
    "control_ts_data = parkinson.utils.data.df_to_timeseries(control_atlas_data)\n",
    "parkinson_ts_data = parkinson.utils.data.df_to_timeseries(parkinson_atlas_data)\n",
    "\n",
    "# Mixing Control/Parkinson pacients and changing NaN values to zero.\n",
    "X = parkinson.utils.data.concatenate_data(parkinson_ts_data, control_ts_data)\n",
    "y = parkinson.utils.data.concatenate_data([1 for _ in range(len(parkinson_data))], [0 for _ in range(len(control_data))])\n",
    "X, y = parkinson.utils.data.filter_data(X, y)\n",
    "\n",
    "# Spliting data into 60 train, 20 validation and 20 test.\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, random_state=RDN, stratify=y, shuffle=True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.25, random_state=RDN, stratify=y_trainval, shuffle=True)\n",
    "\n",
    "# Applying Oversampling in the train set.\n",
    "orig_shape = X_train.shape\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "\n",
    "smote = SMOTE(random_state=RDN)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "X_train = X_train.reshape(-1, *orig_shape[1:])\n",
    "\n",
    "# Creating DataLoader\n",
    "train_loader = parkinson.utils.data.get_torch_dataloader(X_train, y_train, batch_size=BATCH_SIZE)\n",
    "val_loader = parkinson.utils.data.get_torch_dataloader(X_val, y_val, batch_size=BATCH_SIZE)\n",
    "test_loader = parkinson.utils.data.get_torch_dataloader(X_test, y_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ef1502",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dcef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = parkinson.NetworkModels.tsFCN(X_train.shape[1], N_CLASSES)\n",
    "\n",
    "model.train()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "out = parkinson.utils.train.train(model, train_loader, val_loader, device, N_EPOCHS, PATIENCE, LR, DECAY)\n",
    "\n",
    "metrics = parkinson.utils.train.evaluate(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84663c6e",
   "metadata": {},
   "source": [
    "# Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac743d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando e plotando os resultados.\n",
    "parkinson.utils.results.metrics_to_dataframe(metrics)\n",
    "fig_loss = parkinson.utils.results.plot_losses(out['train_loss'],out['val_loss'])\n",
    "fig_loss.show()\n",
    "fig_cf = parkinson.utils.results.plot_confusion_matrix(metrics['preds'], metrics['labels'], class_names=['Control','Parkinson'])\n",
    "fig_cf.show()\n",
    "\n",
    "# Salvando as figuras.\n",
    "fig_loss.savefig(f\"{SAVE_PATH}/loss_curve.png\", bbox_inches='tight')\n",
    "fig_cf.savefig(f\"{SAVE_PATH}/confusion_matrix.png\", bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eniac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
