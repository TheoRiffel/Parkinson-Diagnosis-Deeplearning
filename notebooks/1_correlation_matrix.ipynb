{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9533b8be",
   "metadata": {},
   "source": [
    "# Correlation Matrix with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4d47b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affa8df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('..')\n",
    "!export PYTHONPATH=$(pwd):$PYTHONPATH\n",
    "\n",
    "import parkinson\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28f7899",
   "metadata": {},
   "outputs": [],
   "source": [
    "RDN = 50\n",
    "N_CLASSES = 2\n",
    "BATCH_SIZE = 32\n",
    "N_EPOCHS = 200\n",
    "PATIENCE = 20\n",
    "LR = 0.0001\n",
    "CORR_METHOD = \"sliding_window\"  # método de matriz de correlação: dtw, pearson, spearman, icoh (no graph.py)\n",
    "SAVE_PATH = 'outputs/1_correlation_matrix'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccc346b",
   "metadata": {},
   "source": [
    "# Processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3806cc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lendo os arquivos de dados\n",
    "parkinson_data = parkinson.utils.data.batch_read('data/PDs_columns')\n",
    "control_data = parkinson.utils.data.batch_read('data/Controls_columns') \n",
    "\n",
    "# selecionando as colunas de atlas AAL3, o atlas de conectividade cerebral\n",
    "control_atlas_data = parkinson.utils.data.select_atlas_columns(control_data, 'AAL3')\n",
    "parkinson_atlas_data = parkinson.utils.data.select_atlas_columns(parkinson_data, 'AAL3')\n",
    "\n",
    "# Geração da matriz de correlação utilizando o método especificado para o grupo de Parkinson\n",
    "parkinson_correlation_matrix = parkinson.utils.graph.compute_correlation_matrix(\n",
    "    parkinson_atlas_data, method=CORR_METHOD, group='parkinson'\n",
    ")\n",
    "\n",
    "# Geração da matriz de correlação utilizando o método especificado para o grupo controle\n",
    "control_correlation_matrix = parkinson.utils.graph.compute_correlation_matrix(\n",
    "    control_atlas_data, method=CORR_METHOD, group='control'\n",
    ")\n",
    "\n",
    "# Concatenando grupo controle e grupo de Parkinson\n",
    "# e filtrando os dados para remover entradas com NaN ou infinitos\n",
    "X = parkinson.utils.data.concatenate_data(parkinson_correlation_matrix, control_correlation_matrix)\n",
    "y = parkinson.utils.data.concatenate_data([1 for _ in range(len(parkinson_data))], [0 for _ in range(len(control_data))])\n",
    "X, y = parkinson.utils.data.filter_data(X, y)\n",
    "\n",
    "# Dividindo os dados em 60 para treino, 20 para validação e 20 para teste\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, random_state=RDN, stratify=y, shuffle=True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.25, random_state=RDN, stratify=y_trainval, shuffle=True)\n",
    "\n",
    "# Aplicando oversampling no conjunto de treino\n",
    "ros = RandomOverSampler(random_state=RDN)\n",
    "X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Criando DataLoaders\n",
    "train_loader = parkinson.utils.data.get_torch_dataloader(X_train, y_train, batch_size=BATCH_SIZE)\n",
    "val_loader = parkinson.utils.data.get_torch_dataloader(X_val, y_val, batch_size=BATCH_SIZE)\n",
    "test_loader = parkinson.utils.data.get_torch_dataloader(X_test, y_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf5fe79",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eea3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = parkinson.NetworkModels.SimpleMLP(input_dim=X_train.shape[1], hidden_dim=16, output_dim=2)\n",
    "class_weights = parkinson.utils.data.get_torch_class_weights(y_train)\n",
    "\n",
    "model.train()\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "\n",
    "out = parkinson.utils.train.train(model, train_loader, val_loader, device, N_EPOCHS, PATIENCE, LR, class_weights=class_weights)\n",
    "\n",
    "metrics = parkinson.utils.train.evaluate(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9d9f8c",
   "metadata": {},
   "source": [
    "# Análise dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b169a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando e plotando os resultados.\n",
    "parkinson.utils.results.metrics_to_dataframe(metrics)\n",
    "fig_loss = parkinson.utils.results.plot_losses(out['train_loss'],out['val_loss'])\n",
    "fig_loss.show()\n",
    "fig_cf = parkinson.utils.results.plot_confusion_matrix(metrics['preds'], metrics['labels'], class_names=['Control','Parkinson'])\n",
    "fig_cf.show()\n",
    "\n",
    "# Salvando as figuras.\n",
    "fig_loss.savefig(f\"{SAVE_PATH}/loss_curve.png\", bbox_inches='tight')\n",
    "fig_cf.savefig(f\"{SAVE_PATH}/confusion_matrix.png\", bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trabRN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
